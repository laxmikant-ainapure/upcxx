"""
This is a nobs rule-file. See nobs/nobs/ruletree.py for documentation
on the structure and interpretation of a rule-file.
"""

import os
import sys

import shlex
shplit = shlex.split

from nobs import errorlog
from nobs import os_extra
from nobs import subexec

cxx_exts = ('.cpp','.cxx','.c++','.C','.C++')
c_exts = ('.c',)
header_exts = ('.h','.hpp','.hxx','.h++')

crawlable_dirs = [
  here('src'),
  here('test')
]

"""
Library sets are encoded as a dictionary of strings to dictionaries
conforming to:
  {libname:str: {
      'primary':bool # defaults to True if absent
      'ld':[str],
      'incdirs':[str], # "-I" directories
      'incfiles':[str] # paths to files residing in "-I" directories.
      'ppflags':[str], # preprocessor flags to compiler minus those necessary for `incdirs` and `incfiles`
      'cgflags':[str], # code-gen flags to compiler
      'ldflags':[str], # flags to ld
      'libfiles':[str], # paths to binary archives
      'libflags':[str], # "-L", "-l", and other trailing linker flags minus those for `libfiles`
      'deplibs':[str] # short-names for dependencies of this library
    }, ...
  }

Each key is the short name of the library (like 'm' for 
'libm') and the value is a dictionary containing the linker command, 
various flags lists, and the list of libraries short-names it is 
dependent on.

Primary libraries are those which are used directly by the consumer,
while non-primary libraries are the secondary dependencies.

`incdirs`, `incfiles` and `libfiles` are not included in the `ppflags`
and `libflags` flag lists. `libset_*flags` queries exist at the bottom of
this file for properly retrieving complete flag lists.

Other routines for manipulating library-sets (named libset_*) exist at
the bottom of this file as well.
"""

@cached
def output_of(cmd_args):
  """
  Returns (returncode,stdout,stderr) generated by invoking the command
  arguments as a child process.
  """
  try:
    import subprocess as sp
    p = sp.Popen(cmd_args, stdin=sp.PIPE, stdout=sp.PIPE, stderr=sp.PIPE)
    stdout, stderr = p.communicate()
    return (p.returncode, stdout, stderr)
  except OSError as e:
    return (e.errno, None, None)

@rule(cli='cxx')
@coroutine
def cxx(cxt):
  """
  String list for the C++ compiler.
  """
  _, cross_env = yield cxt.gasnet_config()
  ans_cross = shplit(cross_env.get('CXX',''))
  
  ans_default = []
  if env('CRAYPE_DIR', None):
    ans_default = ['CC']
  if not ans_default:
    ans_default = ['g++']
  
  ans_user = shplit(env('CXX',''))
  
  if ans_cross and ans_user and ans_user != ans_cross:
    errorlog.warning(
      "Cross C++ compiler (%s) differs from CXX environment variable (%s)." % (
        ' '.join(ans_cross),
        ' '.join(ans_user)
      )
    )
  
  # If the cross-config script set it, use it.
  # Otherwise honor the CXX env-variable.
  # Otherwise use intelligent defaults.
  yield ans_cross or ans_user or ans_default

@rule(cli='cc')
@coroutine
def cc(cxt):
  """
  String list for the C compiler.
  """
  _, cross_env = yield cxt.gasnet_config()
  ans_cross = shplit(cross_env.get('CC',''))
  
  ans_default = []
  if env('CRAYPE_DIR', None):
    ans_default = ['cc']
  if not ans_default:
    ans_default = ['gcc']
  
  ans_user = shplit(env('CC',''))
  
  if ans_cross and ans_user and ans_user != ans_cross:
    errorlog.warning(
      "Cross C compiler (%s) differs from CC environment variable (%s)." % (
        ' '.join(ans_cross),
        ' '.join(ans_user)
      )
    )
  
  # If the cross-config script set it, use it.
  # Otherwise honor the CC env-variable.
  # Otherwise use intelligent defaults.
  yield ans_cross or ans_user or ans_default

@rule(cli='ldflags')
def ldflags(cxt):
  return shplit(env('LDFLAGS',''))

@rule()
def lang_c11(cxt):
  """
  String list to engage C11 language dialect for the C compiler.
  """
  return ['-std=c11']

@rule()
def lang_cxx11(cxt):
  """
  String list to engage C++11 language dialect for the C++ compiler.
  """
  return ['-std=c++11']

@rule(path_arg='src')
@coroutine
def comp_lang(cxt, src):
  """
  File-specific compiler with source-language dialect flags.
  """
  _, ext = os.path.splitext(src)
  
  if ext in cxx_exts:
    cxx = yield cxt.cxx()
    yield cxx + cxt.lang_cxx11()
  elif ext in c_exts:
    cc = yield cxt.cc()
    yield cc + cxt.lang_c11()
  else:
    raise Exception("Unrecognized source file extension: "+src)

def version_of(cmd):
  return output_of(cmd + ['--version'])

@rule(path_arg='src')
@coroutine
def comp_version(cxt, src):
  """
  Identity string of file-specific compiler.
  """
  _, ext = os.path.splitext(src)
  
  if ext in cxx_exts:
    cxx = yield cxt.cxx()
    yield version_of(cxx)
  elif ext in c_exts:
    cc = yield cxt.cc()
    yield version_of(cc)
  else:
    raise Exception("Unrecognized source file extension: "+src)

@rule(path_arg='src')
@coroutine
def comp_lang_pp(cxt, src):
  """
  File-specific compiler with source-language and preprocessor flags.
  """
  comp = yield cxt.comp_lang(src)
  ivt = yield cxt.include_vdirs_tree(src)
  libs = yield cxt.libraries(src)
  yield (
    comp + 
    ['-D_GNU_SOURCE=1'] + # Required for full latest POSIX on some systems
    ['-I'+ivt] +
    libset_ppflags(libs)
  )

def upcxx_backend_id():
  return env("UPCXX_BACKEND", otherwise="gasnet1_seq")

@rule()
@coroutine
def upcxx_backend(cxt):
  """
  A pseudo-library used to inject the "-DUPCXX_BACKEND=X" preprocessor
  flag and to rope in gasnet.
  """
  upcxx_be = {
    'upcxx-backend': {
      'ppflags': ['-D%s=%s'%('UPCXX_BACKEND', upcxx_backend_id())],
      'libflags': [],
      'deplibs': ['gasnet','pthread']
    }
  }
  
  gasnet = yield cxt.gasnet()
  
  yield libset_merge(upcxx_be, libset_as_secondary(gasnet))

@rule()
def cg_optlev_default(cxt):
  """
  The default code-gen optimization level for compilation. Reads the
  "OPTLEV" environment variable.
  """
  return env('OPTLEV', 2)

@rule(cli='cg_optlev', path_arg='src')
def cg_optlev(cxt, src):
  """
  File-specific code-gen optimization level, defaults to `cg_optlev_default`.
  """
  return cxt.cg_optlev_default()

@rule()
def cg_dbgsym(cxt):
  """
  Include debugging symbols.
  """
  return env('DBGSYM', 0)

@rule(cli='comp_lang_pp_cg', path_arg='src')
@coroutine
def comp_lang_pp_cg(cxt, src):
  """
  File-specific compiler with language, preprocessor, and code-gen flags.
  """
  comp = yield cxt.comp_lang_pp(src)
  optlev = cxt.cg_optlev(src)
  dbgsym = cxt.cg_dbgsym()
  libset = yield cxt.libraries(src)
  
  yield (
    comp +
    ['-O%d'%optlev] +
    (['-g'] if dbgsym else []) +
    ['-Wall'] +
    libset_cgflags(libset)
  )

@rule(path_arg='src')
@coroutine
def compiler(cxt, src):
  """
  File-specific compiler lambda. Given a source file path, returns a
  function that given a path of where to place the object file, returns
  the argument list to invoke as a child process.
  """
  comp = yield cxt.comp_lang_pp_cg(src)
  
  yield lambda outfile: comp + ['-c', src, '-o', outfile]

# Rule overriden in sub-nobsrule files.
@rule(cli='requires_gasnet', path_arg='src')
def requires_gasnet(cxt, src):
  return False

# Rule overriden in sub-nobsrule files.
@rule(cli='requires_upcxx_backend', path_arg='src')
def requires_upcxx_backend(cxt, src):
  return False

# Rule overriden in sub-nobsrule files.
@rule(cli='requires_pthread', path_arg='src')
def requires_pthread(cxt, src):
  return False

@rule(path_arg='src')
@coroutine
def libraries(cxt, src):
  """
  File-specific library set required to compile and eventually link the
  file `src`.
  """
  if cxt.requires_gasnet(src):
    maybe_gasnet = yield cxt.gasnet()
  else:
    maybe_gasnet = {}
  
  if cxt.requires_upcxx_backend(src):
    maybe_upcxx_backend = yield cxt.upcxx_backend()
  else:
    maybe_upcxx_backend = {}
  
  if cxt.requires_pthread(src):
    maybe_pthread = {'pthread':{}}
  else:
    maybe_pthread = {}
  
  yield cxt.libset_merge(maybe_gasnet, maybe_upcxx_backend, maybe_pthread)

@rule()
def gasnet_user(cxt):
  value = env('GASNET', None)
  
  if not value:
    default_gasnetex_url_b64 = 'aHR0cDovL2dhc25ldC5sYmwuZ292L0VYL0dBU05ldC0yMDE3LjkuMC50YXIuZ3o='
    import base64
    value = base64.b64decode(default_gasnetex_url_b64)
  
  from urlparse import urlparse
  isurl = urlparse(value).netloc != ''
  if isurl:
    return 'tarball-url', value
  
  if not os_extra.exists(value):
    raise errorlog.LoggedError("Non-existent path for GASNET="+value)
  
  value = os.path.abspath(value)
  join = os.path.join
  
  if os_extra.isfile(value):
    return 'tarball', value
  elif os_extra.exists(join(value, 'Makefile')):
    return 'build', value
  elif os_extra.exists(join(value, 'include')) and \
       os_extra.exists(join(value, 'lib')):
    return 'install', value
  elif os_extra.exists(join(value, 'configure')):
    return 'source', value
  else:
    raise errorlog.LoggedError("Invalid value for GASNET (GASNET=%s)"%value)

@rule(cli='gasnet_user_kind')
def gasnet_user_kind(cxt):
  kind, _ = cxt.gasnet_user()
  return kind

@rule(cli='gasnet_conduit')
def gasnet_conduit(cxt):
  """
  GASNet conduit to use.
  """
  if env('CROSS','').startswith('cray-aries-'):
    default = 'aries'
  else:
    default = 'smp'
  
  return env('GASNET_CONDUIT', None) or default

@rule(cli='gasnet_syncmode')
def gasnet_syncmode(cxt):
  """
  GASNet sync-mode to use.
  """
  return {
      'gasnet1_seq': 'seq',
      'gasnetex_par': 'par'
    }[upcxx_backend_id()]

@rule(cli='gasnet_syncmode')
def gasnet_debug(cxt):
  """
  Whether to build GASNet in debug mode.
  """
  return cxt.cg_dbgsym()

@rule(cli='gasnet_install_to')
def gasnet_install_to(cxt):
  """
  User-requested install location for gasnet.
  """
  path_fmt = env('GASNET_INSTALL_TO', None)
  
  if path_fmt is None:
    return None
  else:
    path = path_fmt.format(debug=(1 if cxt.gasnet_debug() else 0))
    path = os.path.expanduser(path)
    path = os.path.abspath(path)
    return path

@rule(cli='include_vdirs', path_arg='src')
def include_vdirs(cxt, src):
  return {'upcxx': here('src')}

@rule_memoized(path_arg=0)
class include_vdirs_tree:
  """
  Setup a shim directory containing a symlink for each vdir in
  include_vdirs. With this directory added via '-I...' to
  compiler flags, allows our headers to be accessed via:
    #include <upcxx/*.hpp>
  """
  version_bump = 0
  
  @traced
  def get_include_vdirs(me, cxt, src):
    return cxt.include_vdirs(src)
  
  def execute(me):
    vdirs = me.get_include_vdirs()
    return me.mktree(vdirs, symlinks=True)

@rule_memoized(cli='incs', path_arg=0)
class includes:
  """
  Ask compiler for all the non-system headers pulled in by preprocessing
  the given source file. Returns the list of paths to included files.
  """
  version_bump = 0
  
  @traced
  @coroutine
  def get_stuff(me, cxt, src):
    me.depend_files(src)
    
    version = yield cxt.comp_version(src)
    me.depend_fact(key=None, value=version)
    
    comp_pp = yield cxt.comp_lang_pp(src)
    
    yield comp_pp, src
  
  @coroutine
  def execute(me):
    comp_pp, src = yield me.get_stuff()
    
    # See here for getting this to work with other compilers:
    #  https://projects.coin-or.org/ADOL-C/browser/trunk/autoconf/depcomp?rev=357
    cmd = comp_pp + ['-MM','-MT','x',src]
    
    mk = yield subexec.launch(cmd, capture_stdout=True)
    mk = mk[mk.index(":")+1:]
    
    deps = shplit(mk.replace("\\\n",""))[1:] # first is source file
    deps = map(os.path.abspath, deps)
    me.depend_files(*deps)
    
    yield deps

@rule_memoized(cli='obj', path_arg=0)
class compile:
  """
  Compile the given source file. Returns path to object file.
  """
  version_bump = 0
  
  @traced
  @coroutine
  def get_src_compiler(me, cxt, src):
    compiler = yield cxt.compiler(src)
    version = yield cxt.comp_version(src)
    
    me.depend_fact(key='compiler', value=version)
    
    includes = yield cxt.includes(src)
    me.depend_files(src)
    me.depend_files(*includes)
    
    yield src, compiler
  
  @coroutine
  def execute(me):
    src, compiler = yield me.get_src_compiler()
    
    objfile = me.mkpath(None, suffix=os.path.basename(src)+'.o')
    yield subexec.launch(compiler(objfile))
    yield objfile

@rule_memoized(path_arg=0)
class objects_and_libset:
  """
  Compile the given source file as well as all source files which can
  be found as sharing its name with a header included by any source
  file reached in this process (transitively closed set). Return pair
  containing set of all object files and the accumulated library
  dependency set.
  """
  @traced
  def get_main_src(me, cxt, main_src):
    return main_src
  
  @traced
  def do_includes(me, cxt, main_src, src):
    return cxt.includes(src)
  
  @traced
  def do_compile_and_libraries(me, cxt, main_src, src):
    return futurize(cxt.compile(src), cxt.libraries(src))
  
  @traced
  def find_src_exts(me, cxt, main_src, base):
    def exists(ext):
      path = base + ext
      me.depend_files(path)
      return os_extra.exists(path)
    srcs = filter(exists, c_exts + cxx_exts)
    return srcs
  
  @coroutine
  def execute(me):
    main_src = me.get_main_src()
    
    # compile object files
    incs_seen = set()
    objs = []
    libset = {}
    
    def fresh_src(src):
      return async.when_succeeded(
        me.do_includes(src) >> includes_done,
        me.do_compile_and_libraries(src) >> compile_done
      )
    
    def includes_done(incs):
      tasks = []
      for inc in incs:
        inc = os_extra.realpath(inc)
        if inc not in incs_seen:
          incs_seen.add(inc)
          inc_base, _ = os.path.splitext(inc)
          # `inc` must be in a crawlable directory
          if any(path_within_dir(inc_base, x) for x in crawlable_dirs):
            for ext in me.find_src_exts(inc_base):
              src = inc_base + ext
              # Don't compile source files which have been included
              # into other source files.
              if src not in incs_seen:
                tasks.append(fresh_src(src))
      
      return async.when_succeeded(*tasks)
    
    def compile_done(obj, more_libs):
      objs.append(obj)
      libset_merge_inplace(libset, more_libs)
    
    # wait for all compilations
    yield fresh_src(main_src)
    
    # return pair
    yield (objs, libset)

@rule_memoized(cli='exe', path_arg=0)
class executable:
  """
  Compile the given source file as well as all source files which can
  be found as sharing its name with a header included by any source
  file reached in this process (transitively closed set). Take all those
  compiled object files and link them along with their library
  dependencies to proudce an executable. Path to executable returned.
  """
  version_bump = 2
  
  @traced
  def cxx(me, cxt, main_src):
    return cxt.cxx()
  
  @traced
  def ldflags(me, cxt, main_src):
    return cxt.ldflags()
  
  @traced
  def objects_and_libset(me, cxt, main_src):
    return cxt.objects_and_libset(main_src)
  
  @coroutine
  def execute(me):
    objs, libset = yield me.objects_and_libset()
    
    # link
    exe = me.mkpath('exe', suffix='.x')
    
    ld = libset_ld(libset)
    if ld is None:
      ld = yield me.cxx()
    
    ldflags = me.ldflags() + libset_ldflags(libset)
    libflags = libset_libflags(libset)
    
    yield subexec.launch(ld + ldflags + ['-o',exe] + objs + libflags)
    yield exe

@rule_memoized(cli='lib', path_arg=0)
class library:
  version_bump = 7
  
  @traced
  def get_main_src(me, cxt, main_src):
    return main_src
  
  @traced
  def includes(me, cxt, main_src, src):
    return cxt.includes(src)
  
  @traced
  def objects_and_libset(me, cxt, main_src):
    return cxt.objects_and_libset(main_src)
  
  @traced
  def get_include_vdirs_and_tree(me, cxt, main_src):
    return futurize(
      cxt.include_vdirs(main_src),
      cxt.include_vdirs_tree(main_src)
    )
  
  @coroutine
  def execute(me):
    main_src = me.get_main_src()
    top_dir = here()
    
    objs, libset = yield me.objects_and_libset()
    
    # Headers pulled in from main file. Discard those not within this
    # repo (top_dir) or the nobs artifact cache (path_art).
    incs = yield me.includes(main_src)
    incs = map(os_extra.realpath, incs)
    incs = [i for i in incs if
      path_within_dir(i, top_dir) or
      path_within_dir(i, me.memodb.path_art)
    ]
    incs = list(set(incs))
    
    inc_vdirs, inc_vdirs_tree = yield me.get_include_vdirs_and_tree()
    
    # Reconstruct paths to includes as relative to vdirs in case the
    # symlinks get squashed out.
    incs1 = []
    updir = '..' + os.path.sep
    for inc in incs:
      candidates = []
      for vsym, vreal in inc_vdirs.items():
        rel = os.path.relpath(inc, vreal)
        if not rel.startswith(updir):
          candidates.append(os.path.join(inc_vdirs_tree, vsym, rel))
      candidates.sort(key=len)
      incs1.append(candidates[0] if len(candidates) != 0 else inc)
    incs = incs1
    
    par_dir = me.mkpath(key=None)
    os.makedirs(par_dir)
    
    libname, _ = os.path.splitext(main_src)
    libname = os.path.basename(libname)
    
    libpath = os.path.join(par_dir, 'lib' + libname + '.a')
    
    # archive objects to `libpath`
    yield subexec.launch(['ar', 'rcs', libpath] + objs)
    
    yield libset_merge(
      libset_as_secondary(libset),
      {libname: {
        'incdirs': [inc_vdirs_tree],
        'incfiles': incs,
        'libfiles': [libpath],
        'deplibs': list(libset.keys())
      }}
    )

@rule(cli='run', path_arg='main_src')
@coroutine
def run(cxt, main_src, *args):
  """
  Build the executable for `main_src` and run it with the given
  argument list `args`.
  """
  _, libset = yield cxt.objects_and_libset(main_src)
  exe = yield cxt.executable(main_src)
  
  if 'gasnet' in libset:
    meta = libset['gasnet']['meta']
    
    env1 = dict(os.environ)
    env1['GASNET_PREFIX'] = meta.get('GASNET_INSTALL') or meta.get('GASNET_BUILD')
    if meta['GASNET_CONDUIT'] == 'udp':
      env1['GASNET_SPAWNFN'] = env('GASNET_SPAWNFN','L')
    
    upcxx_run = here('utils','upcxx-run')
    ranks = str(env('RANKS', 1))
    
    os.execvpe(upcxx_run, [upcxx_run, ranks, exe] + map(str, args), env1)
  else:
    os.execvp(exe, [exe] + map(str, args))

@rule(cli='install', path_arg='main_src')
@coroutine
def install(cxt, main_src, install_path):
  libset = yield cxt.library(main_src)
  
  # select name of the one primary library
  name = [k for k,v in libset.items() if v['primary']]
  assert len(name) == 1
  name = name[0]
  
  cc = yield cxt.cc()
  cxx = yield cxt.cxx()
  
  install_libset(install_path, name, libset, meta_extra={
    'CC': ' '.join(cc),
    'CXX': ' '.join(cxx)
  })
  
  yield None

########################################################################
## GASNet build recipes                                               ##
########################################################################

@rule_memoized()
class gasnet_source:
  """
  Download and extract gasnet source tree.
  """
  version_bump = 0
  
  @traced
  def get_gasnet_user(me, cxt):
    return cxt.gasnet_user()
  
  @coroutine
  def execute(me):
    kind, value = me.get_gasnet_user()
    assert kind in ('tarball-url', 'tarball', 'source', 'build')
    
    if kind == 'source':
      source_dir = value
    
    elif kind == 'build':
      build_dir = value
      makefile = os.path.join(build_dir, 'Makefile')
      source_dir = makefile_extract(makefile, 'TOP_SRCDIR')
    
    else: # kind in ('tarball','tarball-url')
      if kind == 'tarball':
        tgz = value
        me.depend_files(tgz) # in case the user changes the tarball but not its path
      else: # kind == 'tarball-url'
        url = value
        tgz = me.mktemp()
        
        @async.launched
        def download():
          import urllib
          urllib.urlretrieve(url, tgz)
        
        print>>sys.stderr, 'Downloading %s' % url
        yield download()
        print>>sys.stderr, 'Finished    %s' % url
      
      untar_dir = me.mkpath(key=None)
      os.makedirs(untar_dir)
      
      import tarfile
      with tarfile.open(tgz) as f:
        source_dir = os.path.join(untar_dir, f.members[0].name)
        f.extractall(untar_dir)
    
    yield source_dir

@rule_memoized()
class gasnet_config:
  """
  Returns (argv:list, env:dict) pair corresponding to the context
  in which gasnet's other/contrib/cross-configure-{xxx} script runs
  configure.
  """
  version_bump = 0
  
  @traced
  @coroutine
  def get_cross_and_gasnet_src(me, cxt):
    cross = env('CROSS', None)
    kind, value = cxt.gasnet_user()
    
    if cross and kind == 'install':
      raise errorlog.LoggedError(
        'Configuration Error',
        'It is invalid to use both cross-compile (CROSS) and ' +
        'externally installed gasnet (GASNET).'
      )
    
    gasnet_src = None
    if cross:
      gasnet_src = yield cxt.gasnet_source()
    
    yield (cross, gasnet_src)
  
  @traced
  def get_env(me, cxt, name):
    """Place dependendcies on environment variables."""
    return env(name, None)
  
  @coroutine
  def execute(me):
    cross, gasnet_src = yield me.get_cross_and_gasnet_src()
    
    if cross is None:
      yield ([], {})
      return
    
    # add "canned" env-var dependencies of scripts here
    if cross == 'cray-aries-slurm':
      me.get_env('SRUN')
    elif cross == 'bgq':
      me.get_env('USE_GCC')
      me.get_env('USE_CLANG')
    
    path = os.path.join
    crosslong = 'cross-configure-' + cross
    crosspath = path(gasnet_src, 'other', 'contrib', crosslong)
    
    if not os_extra.exists(crosspath):
      raise errorlog.LoggedError('Configuration Error', 'Invalid GASNet cross-compile script name (%s).'%cross)
    
    # Create a shallow copy of the gasnet source tree minus the
    # "configure" file.
    tmpd = me.mkdtemp()
    os_extra.mktree(
      tmpd,
      dict([
          (x, path(gasnet_src, x))
          for x in os_extra.listdir(gasnet_src)
          if x != 'configure'
        ] +
        [(crosslong, crosspath)]
      ),
      symlinks=True
    )
    
    # Add our own shim "configure" which will reap the command line args
    # and environment variables and punt them back to stdout.
    with open(path(tmpd, 'configure'), 'w') as f:
      f.write(
"""#!/usr/bin/env python
import os
import sys
sys.stdout.write(repr((sys.argv, os.environ)))
""")
    os.chmod(path(tmpd, 'configure'), 0777)
    
    # Run the cross-configure script.
    import subprocess as subp
    p = subp.Popen([path(tmpd, crosslong)], cwd=tmpd, stdout=subp.PIPE, stdin=subp.PIPE, stderr=subp.STDOUT)
    out, _ = p.communicate('')
    if p.returncode != 0:
      raise errorlog.LoggedError('Configuration Error', 'GASNet cross-compile script (%s) failed.'%cross)
    argv, env = eval(out)
    
    # Skip the first argument since that's just "configure".
    argv = argv[1:]
    
    # Only record the environment delta.
    keep = ('CC','CXX','HOST_CC','HOST_CXX',
            'MPI_CC','MPI_CFLAGS','MPI_LIBS','MPIRUN_CMD')
    env0 = os.environ
    for x in env0:
      if x in keep: continue
      if x.startswith('CROSS_'): continue
      if x not in env: continue
      if env[x] != env0[x]: continue
      del env[x]
    
    yield (argv, env)

@rule_memoized()
class gasnet_configured:
  """
  Returns a configured gasnet build directory.
  """
  version_bump = 3
  
  @traced
  def get_gasnet_user(me, cxt):
    return cxt.gasnet_user()
  
  @traced
  @coroutine
  def get_config(me, cxt):
    cc = yield cxt.cc()
    cc_ver = version_of(cc)
    me.depend_fact(key='CC', value=cc_ver)
    
    cxx = yield cxt.cxx()
    cxx_ver = version_of(cxx)
    me.depend_fact(key='CXX', value=cxx_ver)
    
    config = yield cxt.gasnet_config()
    source_dir = yield cxt.gasnet_source()
    
    debug = cxt.gasnet_debug()
    user_args = shplit(env('GASNET_CONFIGURE_ARGS',''))
    
    yield (cc, cxx, debug, config, source_dir, user_args)
  
  @coroutine
  def execute(me):
    kind, value = yield me.get_gasnet_user()
    
    if kind == 'build':
      build_dir = value
    else:
      cc, cxx, debug, config, source_dir, user_args = yield me.get_config()
      config_args, config_env = config
      
      build_dir = me.mkpath(key=None)
      os.makedirs(build_dir)
      
      env1 = dict(os.environ)
      env1.update(config_env)
      
      if 'CC' not in env1:
        env1['CC'] = ' '.join(cc)
      if 'CXX' not in env1:
        env1['CXX'] = ' '.join(cxx)
      
      misc_conf_opts = [
        # disable non-EX conduits to prevent configure failures when that hardware is detected
        '--disable-psm','--disable-mxm','--disable-portals4','--disable-ofi',
        # avoid a known issue with -Wnested-externs, until it gets a proper fix in EX
        '--disable-dev-warnings',
        # disable the parsync mode which is not used by UPCXX
        '--disable-parsync',
      ]
      
      print>>sys.stderr, 'Configuring GASNet...'
      yield subexec.launch(
        [os.path.join(source_dir, 'configure')] +
        config_args +
        (['--enable-debug'] if debug else []) +
        misc_conf_opts + user_args,
        
        cwd = build_dir,
        env = env1
      )
    
    yield build_dir

@rule_memoized(cli='gasnet_configured_conduits')
class gasnet_configured_conduits:
  """
  Get the list of detected conduits from a configured gasnet.
  """
  version_bump = 4
  
  @traced
  def get_config(me, cxt):
    kind, value = cxt.gasnet_user()
    return futurize(
      kind,
      value if kind == 'install' else cxt.gasnet_configured()
    )
  
  @coroutine
  def execute(me):
    kind, dir_path = yield me.get_config()
    
    header = os.path.join(*(
      [dir_path] +
      (['include'] if kind == 'install' else []) +
      ['gasnet_config.h']
    ))
    
    import re
    conduits = None
    with open(header,'r') as f:
      for line in f:
        m = re.match('[ \t]*#define +GASNETI_CONDUITS +"([^"]*)"', line)
        if m is not None:
          conduits = m.group(1).split()
          break
        elif 'GASNETI_CONDUITS' in line:
          print>>sys.stderr, repr(line)
    
    assert conduits is not None
    yield conduits
    
@rule_memoized(cli='gasnet_built')
class gasnet_built:
  """
  Build gasnet (if necessary). Return tuple (installed, built_dir) where
  `installed` is a boolean indicating whether `built_dir` points to a
  gasnet install tree or build tree.
  """
  version_bump = 0
  
  @traced
  def get_config(me, cxt):
    kind, value = cxt.gasnet_user()
    install_to = cxt.gasnet_install_to()
    return futurize(
      kind,
      value if kind == 'install' else cxt.gasnet_configured(),
      install_to,
      None if install_to else cxt.gasnet_conduit(),
      None if install_to else cxt.gasnet_syncmode()
    )
  
  @traced
  def cxx(me, cxt):
    return cxt.cxx()
  
  @coroutine
  def execute(me):
    kind, build_or_install_dir, install_to, conduit, syncmode \
      = yield me.get_config()
    
    if kind == 'install':
      installed = True
      built_dir = build_or_install_dir
    else:
      # We weren't given an installed gasnet, so we're looking at a
      # configured build dir.
      build_dir = build_or_install_dir
      
      if install_to is None:
        # We haven't been told to install gasnet to a specific location,
        # so we can build just what we need (conduit,threading)
        print>>sys.stderr, 'Building GASNet (conduit=%s, threading=%s)...'%(conduit, syncmode)
        yield subexec.launch(
          ['make', syncmode],
          cwd = os.path.join(build_dir, '%s-conduit'%conduit)
        )
        
        if conduit == 'udp':
          yield subexec.launch(
            ['make', 'amudprun'],
            cwd = os.path.join(build_dir, 'other', 'amudp')
          )
        
        installed = False
        built_dir = build_or_install_dir
      else:
        # User wants us to install gasnet
        print>>sys.stderr, 'Building GASNet...'
        yield subexec.launch(['make'], cwd=build_dir)
        
        print>>sys.stderr, 'Installing GASNet...'
        yield subexec.launch(
          ['make', 'install', 'prefix='+install_to],
          cwd=build_dir
        )
        installed = True
        built_dir = install_to
    
    yield (installed, built_dir)

@rule_memoized(cli='gasnet')
class gasnet:
  """
  Builds/installs gasnet as necessary. Returns library dependencies dictionary.
  """
  version_bump = 10
  
  @traced
  @coroutine
  def get_config(me, cxt):
    installed, built_dir = yield cxt.gasnet_built()
    cxx = yield cxt.cxx()
    yield (
      installed, built_dir,
      cxt.gasnet_conduit(),
      cxt.gasnet_syncmode(),
      cxx
    )
  
  @coroutine
  def execute(me):
    installed, built_dir, conduit, syncmode, cxx = yield me.get_config()
    
    makefile = os.path.join(*(
      [built_dir] +
      (['include'] if installed else []) +
      ['%s-conduit'%conduit, '%s-%s.mak'%(conduit, syncmode)]
    ))
    
    GASNET_LD = shplit(makefile_extract(makefile, 'GASNET_LD'))
    GASNET_LDFLAGS = shplit(makefile_extract(makefile, 'GASNET_LDFLAGS'))
    GASNET_CXXCPPFLAGS = shplit(makefile_extract(makefile, 'GASNET_CXXCPPFLAGS'))
    GASNET_CXXFLAGS = shplit(makefile_extract(makefile, 'GASNET_CXXFLAGS'))
    GASNET_LIBS = shplit(makefile_extract(makefile, 'GASNET_LIBS'))
    
    # workaround for GASNet not giving us a C++ capable linker.
    GASNET_LD = cxx + GASNET_LD[1:]
    
    if installed:
      # use gasnet install in-place
      incdirs = []
      incfiles = []
      libfiles = []
    else:
      # pull "-I..." arguments out of GASNET_CXXCPPFLAGS
      incdirs = [x for x in GASNET_CXXCPPFLAGS if x.startswith('-I')]
      GASNET_CXXCPPFLAGS = [x for x in GASNET_CXXCPPFLAGS if x not in incdirs]
      incdirs = [x[2:] for x in incdirs] # drop "-I" prefix
      
      makefile = os.path.join(built_dir, 'Makefile')
      source_dir = makefile_extract(makefile, 'TOP_SRCDIR')
      incfiles = shplit(makefile_extract(makefile, 'include_HEADERS'))
      incfiles = [os.path.join(source_dir, i) for i in incfiles]
      
      # pull "-L..." arguments out of GASNET_LIBS, keep only the "..."
      libdirs = [x[2:] for x in GASNET_LIBS if x.startswith('-L')]
      # pull "-l..." arguments out of GASNET_LIBS, keep only the "..."
      libnames = [x[2:] for x in GASNET_LIBS if x.startswith('-l')]
      
      # filter libdirs for those made by gasnet
      libdirs = [x for x in libdirs if path_within_dir(x, built_dir)]
      
      # find libraries in libdirs
      libfiles = []
      libnames_matched = set()
      for libname in libnames:
        lib = 'lib' + libname + '.a'
        for libdir in libdirs:
          libfile = os.path.join(libdir, lib)
          if os.path.exists(libfile):
            # assert same library not found under multiple libdir paths
            assert libname not in libnames_matched
            libfiles.append(libfile)
            libnames_matched.add(libname)
      
      # prune extracted libraries from GASNET_LIBS
      GASNET_LIBS = [x for x in GASNET_LIBS
        if not(
          (x.startswith('-L') and x[2:] in libdirs) or
          (x.startswith('-l') and x[2:] in libnames_matched)
        )
      ]
    
    yield {
      'gasnet': {
        'meta': {
          'GASNET_CONDUIT': conduit,
          'GASNET_INSTALL' if installed else 'GASNET_BUILD': built_dir
        },
        'incdirs': incdirs,
        'incfiles': incfiles,
        'ld': GASNET_LD,
        'ldflags': GASNET_LDFLAGS,
        'ppflags': GASNET_CXXCPPFLAGS,
        'cgflags': GASNET_CXXFLAGS,
        'libfiles': libfiles,
        'libflags': GASNET_LIBS,
        'deplibs': [] # all dependencies flattened into libflags by gasnet
      }
    }

########################################################################
## Utilties                                                           ##
########################################################################

def env(name, otherwise):
  """
  Read `name` from the environment returning it as an integer if it
  looks like one otherwise a string. If `name` does not exist in the 
  environment then `otherwise` is returned.
  """
  try:
    got = os.environ[name]
    try: return int(got)
    except ValueError: pass
    return got
  except KeyError:
    return otherwise

def makefile_extract(makefile, varname):
  """
  Extract a variable's value from a makefile.
  --no-print-directory is required to ensure correct behavior when nobs was invoked by make
  """
  import subprocess as sp
  p = sp.Popen(['make','--no-print-directory','-f','-','gimme'], stdin=sp.PIPE, stdout=sp.PIPE, stderr=sp.PIPE)
  tmp = ('include {0}\n' + 'gimme:\n' + '\t@echo $({1})\n').format(makefile, varname)
  val, _ = p.communicate(tmp)
  if p.returncode != 0:
    raise Exception('Makefile %s not found.'%makefile)
  val = val.strip(' \t\n')
  return val

def path_within_dir(path, dirpath):
  rel = os.path.relpath(path, dirpath)
  return path == dirpath or not rel.startswith('..' + os.path.sep)

########################################################################

def libset_merge_inplace(dst, src):
  """
  Merge libraries of `src` into `dst`.
  """
  
  for k,sv in src.items():
    sv1 = dict(sv)
    try: del sv1['primary']
    except KeyError: pass
    
    dv = dst.get(k,sv)
    dv1 = dict(dv)
    try: del dv1['primary']
    except KeyError: pass
    
    if sv1 != dv1:
      raise Exception("Multiple '%s' libraries with differing configurations." % k)
    
    dv1['primary'] = dv.get('primary',True) or sv.get('primary',True)
    dst[k] = dv1

def libset_merge(*libsets):
  """
  Combine series of libsets into one returned libset.
  """
  ans = {}
  for x in libsets:
    libset_merge_inplace(ans, x)
  return ans

def libset_as_secondary(libset):
  """
  Return new libset with all libraries in set as non-primary (primary=False).
  """
  ans = {}
  for k,v in libset.items():
    if not v.get('primary',True):
      ans[k] = v
    else:
      ans[k] = dict(v)
      ans[k]['primary'] = False
  return ans

def libset_ppflags(libset):
  flags = []
  for rec in libset.values():
    flags.extend(rec.get('ppflags', []))
  for rec in libset.values():
    for d in rec.get('incdirs', []):
      flag = '-I' + d
      if flag not in flags:
        flags.append(flag)
  return flags

def libset_cgflags(libset):
  flags = []
  for rec in libset.values():
    flags.extend(rec.get('cgflags', []))
  return flags

def libset_ld(libset):
  lds = set(tuple(x.get('ld',())) for x in libset.values())
  lds.discard(())
  if len(lds) == 0:
    return None
  if len(lds) != 1:
    raise Exception("Multiple linkers demanded:" + ''.join(map(lambda x:'\n  '+' '.join(x), lds)))
  return list(lds.pop())

def libset_ldflags(libset):
  flags = []
  for rec in libset.values():
    flags.extend(rec.get('ldflags', []))
  return flags

def libset_libflags(libset):
  """
  Generate link-line library flags from a topsort over
  library-library dependencies.
  """
  sorted_lpaths = []
  sorted_flags = []
  visited = set()
  
  def topsort(xs):
    for x in xs:
      rec = libset.get(x, {})
      
      topsort(rec.get('deplibs', []))
      
      if x not in visited:
        visited.add(x)
        
        libfiles = rec.get('libfiles', None)
        libflags = rec.get('libflags', ['-l'+x] if libfiles is None else [])
        libfiles = libfiles or []
        
        sorted_lpaths.append(
          ['-L' + os.path.dirname(f) for f in libfiles]
        )
        sorted_flags.append(
          ['-l' + os.path.basename(f)[3:-2] for f in libfiles] +
          libflags
        )
  
  def uniquify(xs):
    ys = []
    for x in xs:
      if x not in ys:
        ys.append(x)
    return ys
  
  topsort(libset)
  
  sorted_lpaths.reverse()
  sorted_lpaths = sum(sorted_lpaths, [])
  sorted_lpaths = uniquify(sorted_lpaths)
  
  sorted_flags.reverse()
  sorted_flags = sum(sorted_flags, [])
  
  return sorted_lpaths + sorted_flags

def install_libset(install_path, name, libset, meta_extra={}):
  """
  Install a library set to the given path. Produces headers and binaries
  in the typical "install_path/{bin,include,lib}" structure. Also
  creates a metadata retrieval script "bin/${name}-meta" (similar in
  content to a pkgconfig script) for querying the various compiler and
  linker flags.
  """
  import os
  import shutil
  
  base_of = os.path.basename
  join = os.path.join
  updir = '..' + os.path.sep
  
  class InstallError(Exception):
    pass
  
  rollback = []
  commit = []
  suffix = '.771b861d-97e2-49db-b3a2-6d99437726bf'
  
  def ensure_dirs_upto(path):
    head, tail = os.path.split(path)
    if head=='' or os.path.isdir(head):
      return
    if os.path.exists(head):
      raise InstallError('Path "%s" is not a directory.'%head)
    
    ensure_dirs_upto(head)
    
    try:
      os.mkdir(head)
    except OSError as e:
      raise InstallError('Failed to create directory "%s": %s'%(head,e.message))
    
    rollback.append(lambda: os.rmdir(head))
  
  def install_file(src, dst, src_is_path_not_contents=True):
    isfile = os.path.isfile(dst)
    if isfile:
      try:
        os.rename(dst, dst+suffix)
      except OSError as e:
        raise InstallError('Failed to rename "%s": %s".'%(dst,e.message))
      rollback.append((lambda dst: lambda: os.rename(dst+suffix, dst))(dst))
      commit.append((lambda dst: lambda: os.remove(dst+suffix))(dst))
    elif os.path.exists(dst):
      raise InstallError('Path "%s" is not a file.'%path)
    else:
      ensure_dirs_upto(dst)
    
    if not isfile:
      rollback.append((lambda dst: lambda: os.remove(dst))(dst))
    
    try:
      if src_is_path_not_contents:
        shutil.copyfile(src, dst)
      else:
        with open(dst, 'w') as f:
          f.write(src)
      os.chmod(dst, 0755)
    except Exception as e:
      raise InstallError('Could not write file "%s": %s'%(dst, e.message))
  
  def install_contents(contents, dst):
    install_file(contents, dst, src_is_path_not_contents=False)
  
  try:
    libfiles_all = []
    installed_libset = {}
    
    for xname,rec in libset.items():
      incdirs = rec.get('incdirs', [])
      incfiles = rec.get('incfiles', [])
      libfiles = rec.get('libfiles', None)
      
      libfiles_all.extend(libfiles or [])
      
      # produce installed version of library record
      rec1 = dict(rec)
      
      # HACK: copy headers for primary libraries, not otherwise.
      # TODO: We should be tracking header-header dependencies, and
      # then only copying  the set of headers as reachable from the
      # set of primary libraries.
      if rec.get('primary',True):
        incfiles1 = []
        for incf in incfiles:
          # copy for each non-upwards relative path
          for incd in reversed(incdirs):
            rel = os.path.relpath(incf, incd)
            if not rel.startswith(updir):
              # copy include file to relative path under "install_path/include"
              src = join(incd, rel)
              dst = join(install_path, 'include', rel)
              incfiles1.append(dst)
              install_file(src, dst)
        
        rec1['incdirs'] = [join(install_path, 'include')]
        rec1['incfiles'] = incfiles1
      else:
        rec1['incdirs'] = []
        rec1['incfiles'] = []
      
      if libfiles is not None:
        rec1['libfiles'] = [join(install_path, 'lib', base_of(f)) for f in libfiles]
      
      installed_libset[xname] = rec1
    
    # copy libraries
    if len(libfiles_all) != len(set(map(base_of, libfiles_all))):
      raise InstallError(
        'Duplicate library names in list:\n  ' + '\n  '.join(libfiles_all)
      )
    
    for src in libfiles_all:
      dst = join(install_path, 'lib', base_of(src))
      install_file(src, dst)
    
    # build dict of library provided meta-assignments
    metas = dict(meta_extra)
    for rec in installed_libset.values():
      for x,y in rec.get('meta',{}).items():
        assert y == metas.get(x,y) # libraries provided conflicting values for same meta-varaible
        metas[x] = y
    
    # produce metadata script
    meta_path = join(install_path, 'bin', name+'-meta')
    meta_contents = \
'''#!/bin/sh
PPFLAGS="''' + ' '.join(libset_ppflags(installed_libset)) + '''"
LDFLAGS="''' + ' '.join(libset_ldflags(installed_libset)) + '''"
LIBFLAGS="''' + ' '.join(libset_libflags(installed_libset)) + '''"
''' + '\n'.join(
  ["%s='%s'"%(k,v) for k,v in sorted(metas.items()) if v is not None]
) + '''
[ "$1" != "" ] && eval echo '$'"$1"
'''
    install_contents(meta_contents, meta_path)
    
  except Exception as e:
    for fn in reversed(rollback):
      try: fn()
      except OSError: pass
    
    if isinstance(e, InstallError):
      raise errorlog.LoggedError('Installation to "%s" aborted: %s'%(install_path, e.message))
    else:
      raise
  
  else:
    for fn in commit:
      fn()
